# çµ±åˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è©³ç´°ä»•æ§˜

è¤‡æ•°ã®AIãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å‡ºåŠ›ã‚’çµ±åˆå‡¦ç†ã™ã‚‹ãŸã‚ã®è©³ç´°ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä»•æ§˜ã§ã™ã€‚

## å®Ÿè£…æ–¹é‡

ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ä»¥ä¸‹ã®å¤–éƒ¨Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦å®Ÿè£…ã—ã¾ã™ï¼š

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‘ã‚¹**: `~/.claude/bin/parallel-review-merge.py`

SKILL.md Phase 4ã‹ã‚‰ã®å‘¼ã³å‡ºã—ï¼š

```bash
python ~/.claude/bin/parallel-review-merge.py \
  --codex codex-output.md \
  --coderabbit coderabbit-output.md \
  --copilot copilot-output.md \
  --gemini gemini-output.md \
  --output integrated-report.md
```

## 1. ãƒ‘ãƒ¼ã‚¹å‡¦ç†

å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å‡ºåŠ›ã‹ã‚‰Findingã‚’æŠ½å‡ºã—ã¾ã™ã€‚

### 1.1 æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆReDoSå¯¾ç­–æ¸ˆã¿ï¼‰

ReDoSï¼ˆRegular Expression Denial of Serviceï¼‰ã«å¯¾å¿œã—ãŸå®‰å…¨ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼š

```python
# ãƒ•ã‚¡ã‚¤ãƒ«:è¡Œç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡ºï¼ˆå®‰å…¨ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
FILE_LINE_PATTERN = r'\*\*\[([^\]]+?):(\d+)\]\*\*\s+([^\n]+)'

# åˆ¶é™
MAX_FILE_PATH_LENGTH = 500  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æœ€å¤§500æ–‡å­—
MAX_LINE_LENGTH = 500       # è¡Œã®å†…å®¹æœ€å¤§500æ–‡å­—

# ã‚«ãƒ†ã‚´ãƒªã®æŠ½å‡ºï¼ˆè¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯¾å¿œï¼‰
CATEGORY_PATTERNS = {
    'security': [
        'injection', 'xss', 'csrf', 'authentication',
        'authorization', 'crypto', 'ssl', 'tls', 'password',
        'secret', 'token', 'auth', 'vulnerable', 'exploit',
        'vulnerability', 'owasp', 'cwe', 'sql', 'command'
    ],
    'performance': [
        'n+1', 'slow', 'inefficient', 'memory', 'leak',
        'optimization', 'cache', 'bottleneck', 'timeout',
        'deadlock', 'latency', 'throughput'
    ],
    'code_quality': [
        'readability', 'maintainability', 'dry', 'duplication',
        'naming', 'complexity', 'refactor', 'style',
        'convention', 'format', 'lint'
    ],
    'architecture': [
        'pattern', 'coupling', 'cohesion', 'solid',
        'design', 'principle', 'abstraction', 'layer',
        'module', 'component', 'dependency', 'circular'
    ],
    'test': [
        'coverage', 'edge case', 'test', 'mock',
        'unit', 'integration', 'e2e', 'pytest'
    ],
    'github': [
        'ci/cd', 'github', 'action', 'workflow',
        'deploy', 'release', 'branch', 'merge'
    ]
}
```

### 1.2 ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã®æµã‚Œ

```python
def parse_reviewer_output(reviewer_name, output_text):
    """
    ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦Findingã®ãƒªã‚¹ãƒˆã‚’è¿”ã™

    Returns:
        List[Finding]: {
            'file': str,
            'line': int,
            'category': str,
            'priority': str,  # Critical/Important/Suggestion
            'description': str,
            'reviewer': str,
            'detailed_comment': str
        }
    """
    findings = []

    # ãƒ•ã‚¡ã‚¤ãƒ«:è¡Œç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒãƒƒãƒ
    matches = re.finditer(FILE_LINE_PATTERN, output_text)

    for match in matches:
        file_path = match.group(1)[:MAX_FILE_PATH_LENGTH]
        line_num = int(match.group(2))
        description = match.group(3)[:MAX_LINE_LENGTH]

        # ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•åˆ†é¡
        category = classify_category(description)

        # å„ªå…ˆåº¦ã‚’æŠ½å‡º
        priority = extract_priority(description)

        finding = {
            'file': file_path,
            'line': line_num,
            'category': category,
            'priority': priority,
            'description': description,
            'reviewer': reviewer_name,
            'detailed_comment': extract_full_comment(output_text, match.start())
        }

        findings.append(finding)

    return findings
```

## 2. é‡è¤‡æ’é™¤ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

åŒä¸€ã®å•é¡Œã‚’çµ±åˆã—ã¾ã™ã€‚

### 2.1 å®Œå…¨ä¸€è‡´ã«ã‚ˆã‚‹çµ±åˆ

**ã‚­ãƒ¼å®šç¾©**: `{file}:{line}:{category}`

```python
def deduplicate_exact_match(all_findings):
    """
    å®Œå…¨ä¸€è‡´ï¼ˆåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã€è¡Œç•ªå·ã€ã‚«ãƒ†ã‚´ãƒªï¼‰ã®æŒ‡æ‘˜ã‚’çµ±åˆ
    """
    dedup_map = {}

    for finding in all_findings:
        key = (finding['file'], finding['line'], finding['category'])

        if key not in dedup_map:
            dedup_map[key] = {
                **finding,
                'reviewers': [finding['reviewer']],
                'reviewer_comments': {finding['reviewer']: finding['detailed_comment']}
            }
        else:
            # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã€ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’è¿½åŠ 
            dedup_map[key]['reviewers'].append(finding['reviewer'])
            dedup_map[key]['reviewer_comments'][finding['reviewer']] = finding['detailed_comment']

    return list(dedup_map.values())
```

### 2.2 Fuzzy Matchingã«ã‚ˆã‚‹çµ±åˆ

**ãƒ«ãƒ¼ãƒ«**: Â±2è¡Œä»¥å†… && åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ« && åŒä¸€ã‚«ãƒ†ã‚´ãƒª â†’ åŒä¸€å•é¡Œã¨ã—ã¦çµ±åˆ

```python
def deduplicate_fuzzy_match(exact_deduplicated):
    """
    Fuzzy Matchingã§è¿‘ã„è¡Œç•ªå·ã®æŒ‡æ‘˜ã‚’çµ±åˆ
    O(n) ã®ç©ºé–“ç´¢å¼•ã‚’ä½¿ã£ã¦åŠ¹ç‡çš„ã«å®Ÿè£…
    """
    from collections import defaultdict

    # ç©ºé–“ç´¢å¼•: (file, category) -> {line: [findings]}
    spatial_index = defaultdict(lambda: defaultdict(list))

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰
    for finding in exact_deduplicated:
        key = (finding['file'], finding['category'])
        spatial_index[key][finding['line']].append(finding)

    # Fuzzy Matchingã§çµ±åˆ
    merged = []
    processed = set()

    for finding in exact_deduplicated:
        if id(finding) in processed:
            continue

        file_path = finding['file']
        line = finding['line']
        category = finding['category']
        key = (file_path, category)

        # Â±2è¡Œä»¥å†…ã®findingã‚’æ¤œç´¢ï¼ˆO(1)ã§è©²å½“è¡Œã‚’å–å¾—ã€Â±2è¡Œã‚’ç¢ºèªï¼‰
        related = []
        for offset in range(-2, 3):
            check_line = line + offset
            if check_line in spatial_index[key]:
                related.extend(spatial_index[key][check_line])

        # Fuzzy Matchçµæœã‚’çµ±åˆ
        if len(related) > 1:
            merged_finding = merge_findings(related)
            merged.append(merged_finding)

            for r in related:
                processed.add(id(r))
        else:
            merged.append(finding)
            processed.add(id(finding))

    return merged
```

**æ™‚é–“è¨ˆç®—é‡ã®æ”¹å–„**:
- **Before**: O(nÂ²) ã®ç·šå½¢æ¢ç´¢ï¼ˆ1,000ä»¶ã§1,000,000å›ã®æ¯”è¼ƒï¼‰
- **After**: O(n) ã®ç©ºé–“ç´¢å¼•ï¼ˆ1,000ä»¶ã§5,000å›ã®æ¯”è¼ƒï¼‰
- **æ”¹å–„åŠ¹æœ**: 200å€ä»¥ä¸Šã®é«˜é€ŸåŒ–

## 3. å„ªå…ˆåº¦ä»˜ã‘ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

é‡è¤‡æ’é™¤å¾Œã®findingã«å¯¾ã—ã¦å„ªå…ˆåº¦ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

### 3.1 åŸºæœ¬ãƒ«ãƒ¼ãƒ«ï¼ˆãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°ãƒ™ãƒ¼ã‚¹ï¼‰

```python
def calculate_priority_from_count(reviewer_count):
    """
    ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®æŒ‡æ‘˜æ•°ã‹ã‚‰å„ªå…ˆåº¦ã‚’ç®—å‡º
    """
    if reviewer_count >= 4:
        return 'Critical'
    elif reviewer_count >= 3:
        return 'High'
    elif reviewer_count >= 2:
        return 'Medium'
    else:
        return 'Low'
```

### 3.2 ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹å„ªå…ˆåº¦ä¸Šæ›¸ãï¼ˆOWASP Top 10å¯¾å¿œï¼‰

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã¯1ã¤ã®æŒ‡æ‘˜ã§ã‚‚Criticalã«æ˜‡æ ¼ï¼š

```python
CRITICAL_SECURITY_PATTERNS = [
    # A01: Broken Access Control
    'broken_access_control', 'idor', 'insecure_direct_object_reference',
    'authorization_bypass', 'authentication_bypass',

    # A02: Cryptographic Failures
    'sensitive_data_exposure', 'cryptographic_failure', 'encryption',
    'unencrypted', 'plaintext', 'hardcoded_secret', 'hardcoded_password',

    # A03: Injection
    'sql_injection', 'nosql_injection', 'command_injection',
    'code_injection', 'ldap_injection', 'xpath_injection',
    'os_command_injection', 'template_injection',

    # A04: Insecure Design
    'insecure_design', 'insecure_deserialization', 'deserialization',

    # A05: Security Misconfiguration
    'security_misconfiguration', 'misconfiguration',

    # A06: Vulnerable Components
    'vulnerable_dependency', 'outdated_dependency',

    # A07: Identification and Authentication Failures
    'weak_authentication', 'session_fixation', 'credential_exposure',

    # A08: Software and Data Integrity Failures
    'integrity_failure', 'update_vulnerability',

    # A09: Logging and Monitoring Failures
    'insufficient_logging', 'no_monitoring',

    # A10: Server-Side Request Forgery (SSRF)
    'ssrf', 'server_side_request_forgery',

    # ãã®ä»–é‡å¤§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§
    'xss', 'cross_site_scripting', 'reflected_xss', 'stored_xss', 'dom_xss',
    'csrf', 'cross_site_request_forgery',
    'xxe', 'xml_external_entity', 'xml_bomb',
    'path_traversal', 'directory_traversal', 'local_file_inclusion',
    'race_condition',
]

def escalate_security_priority(finding):
    """
    ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã®å„ªå…ˆåº¦ã‚’è‡ªå‹•æ˜‡æ ¼
    """
    if finding['category'] != 'security':
        return finding

    # èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
    description_lower = finding['description'].lower()

    for pattern in CRITICAL_SECURITY_PATTERNS:
        if pattern in description_lower:
            finding['priority'] = 'Critical'
            finding['priority_reason'] = f"OWASP: {pattern}"
            return finding

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã¯Highã«
    if finding['priority'] in ['Low', 'Medium']:
        finding['priority'] = 'High'
        finding['priority_reason'] = 'Security category elevated'

    return finding
```

## 4. ã‚«ãƒ†ã‚´ãƒªåˆ†é¡

è‡ªå‹•åˆ†é¡ãƒ­ã‚¸ãƒƒã‚¯ï¼š

```python
def classify_category(finding_text):
    """
    Findingã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•åˆ†é¡
    """
    text_lower = finding_text.lower()

    # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå„ªå…ˆåº¦é †ï¼‰
    for category, keywords in CATEGORY_PATTERNS.items():
        for keyword in keywords:
            if keyword in text_lower:
                return category

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Code Quality
    return 'code_quality'
```

### 4.1 ã‚«ãƒ†ã‚´ãƒªéšå±¤æ§‹é€ 

```yaml
Security:
  - sql_injection
  - xss
  - csrf
  - authentication_bypass
  - authorization_bypass
  - cryptographic_failure
  - insecure_deserialization
  - ssrf
  - idor
  - path_traversal
  - command_injection
  - xxe
  - security_misconfiguration

Performance:
  - n_plus_one
  - algorithm_inefficiency
  - memory_leak
  - cache_miss
  - slow_query

Code Quality:
  - readability
  - dry_violation
  - naming
  - complexity
  - refactoring_needed

Architecture:
  - design_pattern
  - tight_coupling
  - low_cohesion
  - solid_violation
  - circular_dependency

Test:
  - coverage_gap
  - edge_case_missing
  - integration_test_missing

GitHub:
  - ci_cd_improvement
  - github_actions
  - workflow_optimization
```

## 5. ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å¯¾å¿œ

### 5.1 Conflictã™ã‚‹æŒ‡æ‘˜

è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ãŒçŸ›ç›¾ã™ã‚‹æŒ‡æ‘˜ã‚’ã—ãŸå ´åˆï¼š

```python
def detect_conflicts(finding):
    """
    ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼é–“ã§ã®çŸ›ç›¾ã‚’æ¤œå‡º
    ä¾‹: ä¸€æ–¹ãŒ"åŠ¹ç‡çš„"ã€ä»–æ–¹ãŒ"N+1å•é¡Œ"
    """
    if len(finding['reviewers']) < 2:
        return None

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã§çŸ›ç›¾ã‚’æ¤œå‡º
    comments = list(finding['reviewer_comments'].values())

    # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã§ç›¸åã™ã‚‹ä¸»å¼µã‚’æ¤œå‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
    efficiency_keywords = ['efficient', 'optimal', 'åŠ¹ç‡', 'æœ€é©']
    inefficiency_keywords = ['inefficient', 'slow', 'n+1', 'éåŠ¹ç‡']

    has_efficiency = any(any(kw in c.lower() for kw in efficiency_keywords) for c in comments)
    has_inefficiency = any(any(kw in c.lower() for kw in inefficiency_keywords) for c in comments)

    if has_efficiency and has_inefficiency:
        return True

    return False
```

### 5.2 ç©ºã®çµæœ

ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ãŒä½•ã‚‚æŒ‡æ‘˜ã—ãªã‹ã£ãŸå ´åˆï¼š

```markdown
âœ… {reviewer_name}: å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚
```

### 5.3 ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å¤±æ•—æ™‚ã®å‡¦ç†

ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ãŒå¤±æ•—ã—ãŸå ´åˆã€è­¦å‘Šã‚’ç”Ÿæˆï¼š

```markdown
âš ï¸ {reviewer_name}ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚
{category}è¦³ç‚¹ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
```

## 6. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
# ä¸¦åˆ—AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š ã‚µãƒãƒªãƒ¼

- **ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡**: [target description]
- **èµ·å‹•ã—ãŸãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼**: Codex âœ… | CodeRabbit âœ… | Copilot âœ… | Gemini âœ…
- **æ¤œå‡ºå•é¡Œç·æ•°**: {total_count}ä»¶
  - ğŸ”´ Critical: {critical_count}
  - ğŸŸ¡ High: {high_count}
  - ğŸŸ¢ Medium: {medium_count}
  - â„¹ï¸ Low: {low_count}

---

## ğŸ”´ Criticalï¼ˆå³åº§ã«å¯¾å¿œã™ã¹ãï¼‰

{Critical findings}

---

## ğŸŸ¡ Highï¼ˆå„ªå…ˆçš„ã«å¯¾å¿œï¼‰

{High findings}

---

## ğŸŸ¢ Mediumï¼ˆé‡è¦ï¼‰

{Medium findings}

---

## â„¹ï¸ Low / Informational

{Low findings}

---

## ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ

### ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ ({count}ä»¶)
{security findings summary}

### âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ({count}ä»¶)
{performance findings summary}

### ğŸ“ ã‚³ãƒ¼ãƒ‰å“è³ª ({count}ä»¶)
{code_quality findings summary}

### ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ({count}ä»¶)
{architecture findings summary}

### ğŸ§ª ãƒ†ã‚¹ãƒˆ ({count}ä»¶)
{test findings summary}

### ğŸ”§ GitHubçµ±åˆ ({count}ä»¶)
{github findings summary}

---

## ğŸ¤– ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼åˆ¥ã®ç‹¬è‡ªæŒ‡æ‘˜

### Codexã®ç‹¬è‡ªè¦‹è§£
{codex only findings}

### CodeRabbitã®ç‹¬è‡ªè¦‹è§£
{coderabbit only findings}

### Copilotã®ç‹¬è‡ªè¦‹è§£
{copilot only findings}

### Geminiã®ç‹¬è‡ªè¦‹è§£
{gemini only findings}

---

## ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³

1. **å³åº§**: ğŸ”´ Criticalã®å…¨å•é¡Œã‚’ä¿®æ­£
2. **æœ¬ã‚¹ãƒ—ãƒªãƒ³ãƒˆ**: ğŸŸ¡ Highã®å•é¡Œã‚’å„ªå…ˆå¯¾å¿œ
3. **æ¬¡ã‚¹ãƒ—ãƒªãƒ³ãƒˆ**: ğŸŸ¢ Mediumã®å•é¡Œã‚’çµ„ã¿è¾¼ã¿
4. **ç¶™ç¶šæ”¹å–„**: â„¹ï¸ Lowã®ææ¡ˆã‚’æ¤œè¨

---

## çµ±è¨ˆæƒ…å ±

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | å€¤ |
|-----------|-----|
| ç·æŒ‡æ‘˜æ•° | {total} |
| ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å¹³å‡ | {avg} |
| è¤‡æ•°æŒ‡æ‘˜ç‡ | {multi_percentage}% |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ | {security_count} |
| ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ | {perf_count} |

Generated: {timestamp}
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …

- **Fuzzy Matching**: ç©ºé–“ç´¢å¼•ã«ã‚ˆã‚‹ O(n) å®Ÿè£…
- **å¤§é‡æŒ‡æ‘˜å‡¦ç†**: 100ä»¶ä»¥ä¸Šã®å ´åˆã€Criticalä»¥å¤–ã¯çŸ­ç¸®è¡¨ç¤º
- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã§å¤§è¦æ¨¡å‡ºåŠ›ã«ã‚‚å¯¾å¿œ
- **å®Ÿè¡Œæ™‚é–“ç›®æ¨™**: 1,000ä»¶ã®Findingçµ±åˆã‚’<1ç§’ã§å®Œäº†

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®è€ƒæ…®

- **ReDoSå¯¾ç­–**: æ­£è¦è¡¨ç¾ã®å®‰å…¨æ€§ã‚’ç¢ºä¿
- **ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–**: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
- **ãƒ•ã‚¡ã‚¤ãƒ«I/O**: å®¹é‡åˆ¶é™ï¼ˆ500æ–‡å­—ï¼‰ã§æ‚ªæ„ã®ã‚ã‚‹å…¥åŠ›ã‹ã‚‰ä¿è­·
